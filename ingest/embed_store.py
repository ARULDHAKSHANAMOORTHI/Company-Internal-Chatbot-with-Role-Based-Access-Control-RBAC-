
# from langchain_community.vectorstores import Chroma
# from langchain_huggingface import HuggingFaceEmbeddings
# from ingest.ingest_docs import load_documents, chunk_documents


# # 1Ô∏è‚É£ Load and chunk documents
# docs = load_documents()
# chunks = chunk_documents(docs)

# print("Loaded docs:", len(docs))
# print("Generated chunks:", len(chunks))

# if not chunks:
#     raise ValueError("‚ùå No document chunks found. Check data path and file parsing.")


# # 2Ô∏è‚É£ Prepare texts + metadata
# texts = [c["content"] for c in chunks]
# metadatas = [c["metadata"] for c in chunks]


# # 3Ô∏è‚É£ Create embeddings (ONLY ONCE)
# embeddings = HuggingFaceEmbeddings(
#     model_name="sentence-transformers/all-MiniLM-L6-v2"
# )


# # 4Ô∏è‚É£ Create and persist Chroma DB
# db = Chroma.from_texts(
#     texts=texts,
#     embedding=embeddings,
#     metadatas=metadatas,
#     persist_directory="vector_store/chroma_db"
# )

# db.persist()

# print("‚úÖ Vector DB created successfully")

# import os
# import shutil

# from ingest.ingest_docs import load_documents, chunk_documents
# from langchain_huggingface import HuggingFaceEmbeddings
# from langchain_community.vectorstores import Chroma


# # ==============================
# # CONFIG
# # ==============================
# VECTOR_DIR = "vector_store/chroma_db"


# # ==============================
# # CLEAN OLD VECTOR DB
# # ==============================
# if os.path.exists(VECTOR_DIR):
#     shutil.rmtree(VECTOR_DIR)
#     print("üóëÔ∏è Old vector DB removed")


# # ==============================
# # LOAD + CHUNK DOCUMENTS
# # ==============================
# documents = load_documents()
# chunks = chunk_documents(documents)

# print(f"üìÑ Loaded documents: {len(documents)}")
# print(f"‚úÇÔ∏è Generated chunks: {len(chunks)}")

# if not chunks:
#     raise ValueError("‚ùå No chunks generated. Check data folder and files.")


# # ==============================
# # EMBEDDINGS
# # ==============================
# embeddings = HuggingFaceEmbeddings(
#     model_name="sentence-transformers/all-MiniLM-L6-v2"
# )


# # ==============================
# # CREATE VECTOR STORE
# # ==============================
# db = Chroma.from_documents(
#     documents=chunks,
#     embedding=embeddings,
#     persist_directory=VECTOR_DIR
# )

# db.persist()

# print("‚úÖ Vector DB created successfully with role metadata")


import os
import shutil
from ingest.ingest_docs import load_documents, chunk_documents
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

VECTOR_DIR = "vector_store/chroma_db"

# üî• Clean old vector DB
if os.path.exists(VECTOR_DIR):
    shutil.rmtree(VECTOR_DIR)

print("üìÑ Loading documents...")
docs = load_documents()

print("‚úÇÔ∏è Chunking documents...")
chunks = chunk_documents(docs)

print(f"Docs loaded: {len(docs)}")
print(f"Chunks created: {len(chunks)}")

if not chunks:
    raise RuntimeError("‚ùå No chunks created. Check data path or parsing.")

# üî¢ Embeddings
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

# üì¶ Create vector DB
db = Chroma.from_documents(
    chunks,
    embedding=embeddings,
    persist_directory=VECTOR_DIR
)

db.persist()
print("‚úÖ Vector DB created successfully")
